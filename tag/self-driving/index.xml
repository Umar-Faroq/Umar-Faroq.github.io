<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Self-driving | Min-Hung Chen</title><link>https://minhungchen.netlify.app/tag/self-driving/</link><atom:link href="https://minhungchen.netlify.app/tag/self-driving/index.xml" rel="self" type="application/rss+xml"/><description>Self-driving</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2020 Min-Hung Chen</copyright><lastBuildDate>Tue, 23 Jun 2020 00:00:00 +0000</lastBuildDate><image><url>https://minhungchen.netlify.app/img/authors/head_me.jpg</url><title>Self-driving</title><link>https://minhungchen.netlify.app/tag/self-driving/</link></image><item><title>Traffic Sign Detection under Challenging Conditions</title><link>https://minhungchen.netlify.app/project/curetsd/</link><pubDate>Tue, 23 Jun 2020 00:00:00 +0000</pubDate><guid>https://minhungchen.netlify.app/project/curetsd/</guid><description>&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Existing traffic sign datasets are limited in terms of type and severity of challenging conditions. Metadata corresponding to these conditions are unavailable and it is not possible to investigate the effect of a single factor because of simultaneous changes in numerous conditions. Therefore, we introduce the &lt;strong>CURE-TSD&lt;/strong> dataset, including various challenging conditions with both real and synthetic data.&lt;/p>
&lt;!-- ---
## Challenges
(coming soon)
---
## Our Approaches
(coming soon)
-->
&lt;hr>
&lt;h2 id="dataset-overview">Dataset Overview&lt;/h2>
&lt;ul>
&lt;li>Video number: 5733 videos&lt;/li>
&lt;li>Video length: 300 frames/video (~1.7M total frames in the dataset)&lt;/li>
&lt;li>Challenge types: 12&lt;/li>
&lt;li>Challenge levels: 5
&lt;figure id="figure-challenging-conditions-horizontal-challenge-levels-vertical-challenge-types">
&lt;a data-fancybox="" href="https://minhungchen.netlify.app/project/curetsd/curetsd_challenges_hu05eb8e363895033479e945a3fafedd1b_1062714_2000x2000_fit_lanczos_2.png" data-caption="Challenging conditions (horizontal: challenge levels. vertical: challenge types).">
&lt;img data-src="https://minhungchen.netlify.app/project/curetsd/curetsd_challenges_hu05eb8e363895033479e945a3fafedd1b_1062714_2000x2000_fit_lanczos_2.png" class="lazyload" alt="" width="80%" height="1000">
&lt;/a>
&lt;figcaption>
Challenging conditions (horizontal: challenge levels. vertical: challenge types).
&lt;/figcaption>
&lt;/figure>
&lt;/li>
&lt;li>Traffic sign types: 14
&lt;figure id="figure-traffic-signs-row-1-real-signs-row-2-synthetic-signs">
&lt;a data-fancybox="" href="https://minhungchen.netlify.app/project/curetsd/sign_types_huff92360b86bedc6e357bd78014ffbff6_209212_2000x2000_fit_lanczos_2.png" data-caption="Traffic signs (Row 1: real signs. Row 2: synthetic signs).">
&lt;img data-src="https://minhungchen.netlify.app/project/curetsd/sign_types_huff92360b86bedc6e357bd78014ffbff6_209212_2000x2000_fit_lanczos_2.png" class="lazyload" alt="" width="80%" height="154">
&lt;/a>
&lt;figcaption>
Traffic signs (Row 1: real signs. Row 2: synthetic signs).
&lt;/figcaption>
&lt;/figure>
&lt;/li>
&lt;/ul>
&lt;h3 id="demo-videos">Demo Videos&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Real data:
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/8V1LcpDlmjA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Synthetic data:
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/bKnlJ_EWS8Q" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Please check our
&lt;a href="https://arxiv.org/pdf/1902.06857.pdf" target="_blank" rel="noopener">paper&lt;/a> for more results.&lt;/p>
&lt;hr>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;h4 id="papers--github">Papers &amp;amp; GitHub&lt;/h4>
&lt;p>
&lt;a href="https://github.com/olivesgatech/CURE-TSD" target="_blank" rel="noopener">
&lt;figure id="figure-githubhttpsgithubcomolivesgatechcure-tsd">
&lt;img src="https://minhungchen.netlify.app/img/github_icon.png" alt="" width="15%" >
&lt;figcaption>
&lt;a href="https://github.com/olivesgatech/CURE-TSD">&lt;strong>GitHub&lt;/strong>&lt;/a>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>
&lt;a href="https://arxiv.org/pdf/1908.11262.pdf" target="_blank" rel="noopener">
&lt;figure id="figure-tits19httpsarxivorgpdf190811262pdf">
&lt;img src="https://minhungchen.netlify.app/img/pdf_icon.png" alt="" width="20%" >
&lt;figcaption>
&lt;a href="https://arxiv.org/pdf/1908.11262.pdf">TITS'19&lt;/a>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://arxiv.org/pdf/1902.06857.pdf" target="_blank" rel="noopener">
&lt;figure id="figure-arxiv19httpsarxivorgpdf190206857pdf">
&lt;img src="https://minhungchen.netlify.app/img/pdf_icon.png" alt="" width="20%" >
&lt;figcaption>
&lt;a href="https://arxiv.org/pdf/1902.06857.pdf">arXiv'19&lt;/a>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;/table>
&lt;h4 id="download">Download&lt;/h4>
&lt;p>To download the dataset, please visit our
&lt;a href="https://github.com/olivesgatech/CURE-TSD" target="_blank" rel="noopener">GitHub&lt;/a> or
&lt;a href="https://ieee-dataport.org/open-access/cure-tsd-challenging-unreal-and-real-environment-traffic-sign-detection" target="_blank" rel="noopener">IEEE DataPort&lt;/a>.&lt;/p>
&lt;h4 id="other-links">Other Links&lt;/h4>
&lt;ul>
&lt;li>IEEE Xplore
[
&lt;a href="https://ieeexplore.ieee.org/document/8793235" target="_blank" rel="noopener">TITS'19&lt;/a> ]&lt;/li>
&lt;li>IEEE DataPort
[
&lt;a href="https://ieee-dataport.org/open-access/cure-tsd-challenging-unreal-and-real-environment-traffic-sign-detection" target="_blank" rel="noopener">CURE-TSD&lt;/a> ]&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="related-publications">Related Publications&lt;/h2>
&lt;p>If you find this project useful, please cite our papers (*equal contribution):&lt;/p>
&lt;ul>
&lt;li>Dogancan Temel,
&lt;a href="https://minhungchen.netlify.app/" target="_blank" rel="noopener">&lt;strong>Min-Hung Chen&lt;/strong>&lt;/a>, and Ghassan AlRegib, &amp;ldquo;Traffic Sign Detection under Challenging Conditions: A Deeper Look Into Performance Variations and Spectral Characteristics&amp;rdquo;,
&lt;a href="https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6979" target="_blank" rel="noopener">&lt;em>IEEE Transactions on Intelligent Transportation Systems (TITS)&lt;/em>, 2019&lt;/a>.&lt;/li>
&lt;li>Dogancan Temel, Tariq Alshawi*,
&lt;a href="https://minhungchen.netlify.app/" target="_blank" rel="noopener">&lt;strong>Min-Hung Chen*&lt;/strong>&lt;/a>, and Ghassan AlRegib, &amp;ldquo;Challenging Environments for Traffic Sign Detection: Reliability Assessment under Inclement Conditions&amp;rdquo;, &lt;em>arXiv:1902.06857&lt;/em>, 2019.&lt;/li>
&lt;/ul>
&lt;h4 id="bibtex">BibTex&lt;/h4>
&lt;pre>&lt;code>@article{temel2019traffic,
title={Traffic sign detection under challenging conditions: A deeper look into performance variations and spectral characteristics},
author={Temel, Dogancan and Chen, Min-Hung and AlRegib, Ghassan},
journal={IEEE Transactions on Intelligent Transportation Systems (TITS)},
year={2019},
publisher={IEEE}
}
@article{temel2019challenging,
title={Challenging environments for traffic sign detection: Reliability assessment under inclement conditions},
author={Temel, Dogancan and Alshawi, Tariq and Chen, Min-Hung and AlRegib, Ghassan},
journal={arXiv preprint arXiv:1902.06857},
year={2019},
url={https://arxiv.org/abs/1902.06857}
}
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h2 id="members">Members&lt;/h2>
&lt;p>&lt;strong>Georgia Institute of Technology &lt;br>&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>
&lt;a href="http://cantemel.com/" target="_blank" rel="noopener">
&lt;figure id="figure-dogancan-temel">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_ct.jpg" alt="" width="100%" >
&lt;figcaption>
Dogancan Temel
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://minhungchen.netlify.app/" target="_blank" rel="noopener">
&lt;figure id="figure-min-hung-chen">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_me.jpg" alt="" width="100%" >
&lt;figcaption>
Min-Hung Chen
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://www.linkedin.com/in/tariq-alshawi/" target="_blank" rel="noopener">
&lt;figure id="figure-tariq-alshawi">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_ta.jpg" alt="" width="100%" >
&lt;figcaption>
Tariq Alshawi
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://ghassanalregib.info/" target="_blank" rel="noopener">
&lt;figure id="figure-ghassan-alregib">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_ga.jpg" alt="" width="100%" >
&lt;figcaption>
Ghassan AlRegib
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;/table></description></item><item><title>Interpretable Self-Attention Temporal Reasoning for Driving Behavior Understanding</title><link>https://minhungchen.netlify.app/publication/trb/</link><pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate><guid>https://minhungchen.netlify.app/publication/trb/</guid><description>&lt;!-- &lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -->
&lt;h2 id="resources">Resources&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>
&lt;figure id="figure-paper-arxivhttpsarxivorgftparxivpapers1911191102172pdf">
&lt;a href="https://arxiv.org/ftp/arxiv/papers/1911/1911.02172.pdf">
&lt;img src="https://minhungchen.netlify.app/img/pdf_icon.png" alt="" width="25%" >
&lt;/a>
&lt;figcaption>
&lt;a href="https://arxiv.org/ftp/arxiv/papers/1911/1911.02172.pdf">Paper (arXiv)&lt;/a>
&lt;/figcaption>
&lt;/figure>
&lt;/th>
&lt;th>
&lt;figure id="figure-slideshttpssigportorgsitesdefaultfilesdocsinterpretable20self-attention20temporal20reasoning20for20driving20behavior20understandingpdf">
&lt;a href="https://sigport.org/sites/default/files/docs/INTERPRETABLE%20SELF-ATTENTION%20TEMPORAL%20REASONING%20FOR%20DRIVING%20BEHAVIOR%20UNDERSTANDING.pdf">
&lt;img src="https://minhungchen.netlify.app/img/pdf_icon.png" alt="" width="25%" >
&lt;/a>
&lt;figcaption>
&lt;a href="https://sigport.org/sites/default/files/docs/INTERPRETABLE%20SELF-ATTENTION%20TEMPORAL%20REASONING%20FOR%20DRIVING%20BEHAVIOR%20UNDERSTANDING.pdf">Slides&lt;/a>
&lt;/figcaption>
&lt;/figure>
&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;/table>
&lt;p>Other Links:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://ieeexplore.ieee.org/abstract/document/9053783" target="_blank" rel="noopener">IEEE Xplore&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="citation">Citation&lt;/h2>
&lt;p>
&lt;a href="https://www.linkedin.com/in/ejliu617/" target="_blank" rel="noopener">Yi-Chieh Liu*&lt;/a>,
&lt;a href="https://www.linkedin.com/in/yhsieh37/" target="_blank" rel="noopener">Yung-An Hsieh*&lt;/a>,
&lt;a href="https://minhungchen.netlify.app/" target="_blank" rel="noopener">&lt;strong>Min-Hung Chen&lt;/strong>&lt;/a>,
&lt;a href="https://www.linkedin.com/in/huckyang/" target="_blank" rel="noopener">Chao-Han (Huck) Yang&lt;/a>,
&lt;a href="https://scholar.google.se/citations?hl=en&amp;amp;user=_DUppAgAAAAJ" target="_blank" rel="noopener">Jesper Tegner&lt;/a>, and
&lt;a href="https://scholar.google.com/citations?user=S41zwP4AAAAJ" target="_blank" rel="noopener">Yi-Chang (James) Tsai&lt;/a>, &amp;ldquo;Interpretable Self-Attention Temporal Reasoning for Driving Behavior Understanding&amp;rdquo;,
&lt;a href="https://2020.ieeeicassp.org/" target="_blank" rel="noopener">&lt;em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)&lt;/em>, 2020&lt;/a>. (*equal contribution)&lt;/p>
&lt;h4 id="bibtex">BibTex&lt;/h4>
&lt;pre>&lt;code>@inproceedings{liu2020interpretable,
title={Interpretable Self-Attention Temporal Reasoning for Driving Behavior Understanding},
author={Liu, Yi-Chieh and Hsieh, Yung-An and Chen, Min-Hung and Yang, C-H Huck and Tegner, Jesper and Tsai, Y-C James},
booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
year={2020}
}
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h2 id="members">Members&lt;/h2>
&lt;p>&lt;strong>&lt;sup>1&lt;/sup>Georgia Institute of Technology   &lt;sup>2&lt;/sup>KAUST &lt;br>&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>
&lt;a href="https://www.linkedin.com/in/ejliu617/" target="_blank" rel="noopener">
&lt;figure id="figure-yi-chieh-liusup1sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_ycl.jpg" alt="" width="100%" >
&lt;figcaption>
Yi-Chieh Liu&lt;sup>1&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://www.linkedin.com/in/yhsieh37/" target="_blank" rel="noopener">
&lt;figure id="figure-yung-an-hsiehsup1sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_yah.jpg" alt="" width="100%" >
&lt;figcaption>
Yung-An Hsieh&lt;sup>1&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://minhungchen.netlify.app/" target="_blank" rel="noopener">
&lt;figure id="figure-min-hung-chensup1sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_me.jpg" alt="" width="100%" >
&lt;figcaption>
Min-Hung Chen&lt;sup>1&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://www.linkedin.com/in/huckyang/" target="_blank" rel="noopener">
&lt;figure id="figure-huck-yangsup1sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_chy.jpg" alt="" width="100%" >
&lt;figcaption>
Huck Yang&lt;sup>1&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://scholar.google.se/citations?hl=en&amp;amp;user=_DUppAgAAAAJ" target="_blank" rel="noopener">
&lt;figure id="figure-jesper-tegnersup2sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_jt.jpg" alt="" width="100%" >
&lt;figcaption>
Jesper Tegner&lt;sup>2&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://scholar.google.com/citations?user=S41zwP4AAAAJ" target="_blank" rel="noopener">
&lt;figure id="figure-james-tsaisup1sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_yct.jpg" alt="" width="100%" >
&lt;figcaption>
James Tsai&lt;sup>1&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;/table></description></item><item><title>Color learning</title><link>https://minhungchen.netlify.app/publication/colortsd/</link><pubDate>Tue, 04 Feb 2020 00:00:00 +0000</pubDate><guid>https://minhungchen.netlify.app/publication/colortsd/</guid><description>&lt;!-- &lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -->
&lt;h2 id="citation">Citation&lt;/h2>
&lt;p>
&lt;a href="https://ghassanalregib.info/" target="_blank" rel="noopener">Ghassan AlRegib&lt;/a>,
&lt;a href="https://minhungchen.netlify.app/" target="_blank" rel="noopener">&lt;strong>Min-Hung Chen&lt;/strong>&lt;/a>,
&lt;a href="https://www.linkedin.com/in/david-mccreadie-4b603643/" target="_blank" rel="noopener">David McCreadie&lt;/a>, and
&lt;a href="https://www.linkedin.com/in/bostondaniel/" target="_blank" rel="noopener">Daniel Lewis Boston&lt;/a>, &amp;ldquo;Color learning&amp;rdquo;,
&lt;a href="https://patents.google.com/patent/US10552692B2" target="_blank" rel="noopener">&lt;em>US Patent 10552692&lt;/em>, 2020&lt;/a>.&lt;/p>
&lt;h4 id="bibtex">BibTex&lt;/h4>
&lt;pre>&lt;code>@misc{alregib2020color,
title={Color learning},
author={AlRegib, Ghassan and Chen, Min-Hung and McCreadie, David and },
year={2020},
month=February,
publisher={Google Patents},
note={US Patent 10552692}
}
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h2 id="members">Members&lt;/h2>
&lt;p>&lt;strong>&lt;sup>1&lt;/sup>Georgia Institute of Technology   &lt;sup>2&lt;/sup>Ford Motor Company &lt;br>&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>
&lt;a href="https://ghassanalregib.info/" target="_blank" rel="noopener">
&lt;figure id="figure-ghassan-alregibsup1sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_ga.jpg" alt="" width="100%" >
&lt;figcaption>
Ghassan AlRegib&lt;sup>1&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://minhungchen.netlify.app/" target="_blank" rel="noopener">
&lt;figure id="figure-min-hung-chensup1sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_me.jpg" alt="" width="100%" >
&lt;figcaption>
Min-Hung Chen&lt;sup>1&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://www.linkedin.com/in/david-mccreadie-4b603643/" target="_blank" rel="noopener">
&lt;figure id="figure-david-mccreadiesup2sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_unknown.jpg" alt="" width="100%" >
&lt;figcaption>
David McCreadie&lt;sup>2&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://www.linkedin.com/in/bostondaniel/" target="_blank" rel="noopener">
&lt;figure id="figure-daniel-bostonsup2sup">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_db.jpg" alt="" width="100%" >
&lt;figcaption>
Daniel Boston&lt;sup>2&lt;/sup>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;/table></description></item><item><title>Traffic Sign Detection Under Challenging Conditions: A Deeper Look into Performance Variations and Spectral Characteristics</title><link>https://minhungchen.netlify.app/publication/curetsd/</link><pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate><guid>https://minhungchen.netlify.app/publication/curetsd/</guid><description>&lt;!-- &lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Cite&lt;/em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
&lt;/div>
&lt;/div>
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -->
&lt;h2 id="demo-videos">Demo Videos&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Real data:
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/8V1LcpDlmjA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Synthetic data:
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/bKnlJ_EWS8Q" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;/p>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="resources">Resources&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>
&lt;figure id="figure-githubhttpsgithubcomolivesgatechcure-tsd">
&lt;a href="https://github.com/olivesgatech/CURE-TSD">
&lt;img src="https://minhungchen.netlify.app/img/github_icon.png" alt="" width="65%" >
&lt;/a>
&lt;figcaption>
&lt;a href="https://github.com/olivesgatech/CURE-TSD">&lt;strong>GitHub&lt;/strong>&lt;/a>
&lt;/figcaption>
&lt;/figure>
&lt;/th>
&lt;th>
&lt;a href="https://arxiv.org/pdf/1908.11262.pdf" target="_blank" rel="noopener">
&lt;figure id="figure-paper-arxivhttpsarxivorgpdf190811262pdf">
&lt;img src="https://minhungchen.netlify.app/img/pdf_icon.png" alt="" width="15%" >
&lt;figcaption>
&lt;a href="https://arxiv.org/pdf/1908.11262.pdf">Paper (arXiv)&lt;/a>
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;/table>
&lt;p>Other Links:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://ieeexplore.ieee.org/document/8793235" target="_blank" rel="noopener">IEEE Xplore&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="citation">Citation&lt;/h2>
&lt;p>
&lt;a href="http://cantemel.com/" target="_blank" rel="noopener">Dogancan Temel&lt;/a>,
&lt;a href="https://minhungchen.netlify.app/" target="_blank" rel="noopener">&lt;strong>Min-Hung Chen&lt;/strong>&lt;/a>, and
&lt;a href="https://ghassanalregib.info/" target="_blank" rel="noopener">Ghassan AlRegib&lt;/a>, &amp;ldquo;Traffic Sign Detection under Challenging Conditions: A Deeper Look Into Performance Variations and Spectral Characteristics&amp;rdquo;,
&lt;a href="https://ieeexplore.ieee.org/xpl/aboutJournal.jsp?punumber=6979" target="_blank" rel="noopener">&lt;em>IEEE Transactions on Intelligent Transportation Systems (TITS)&lt;/em>, 2019&lt;/a>.&lt;/p>
&lt;h4 id="bibtex">BibTex&lt;/h4>
&lt;pre>&lt;code>@article{temel2019traffic,
title={Traffic sign detection under challenging conditions: A deeper look into performance variations and spectral characteristics},
author={Temel, Dogancan and Chen, Min-Hung and AlRegib, Ghassan},
journal={IEEE Transactions on Intelligent Transportation Systems (TITS)},
year={2019},
publisher={IEEE}
}
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h2 id="members">Members&lt;/h2>
&lt;p>&lt;strong>Georgia Institute of Technology &lt;br>&lt;/strong>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>
&lt;a href="http://cantemel.com/" target="_blank" rel="noopener">
&lt;figure id="figure-dogancan-temel">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_ct.jpg" alt="" width="100%" >
&lt;figcaption>
Dogancan Temel
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://minhungchen.netlify.app/" target="_blank" rel="noopener">
&lt;figure id="figure-min-hung-chen">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_me.jpg" alt="" width="100%" >
&lt;figcaption>
Min-Hung Chen
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;th>
&lt;a href="https://ghassanalregib.info/" target="_blank" rel="noopener">
&lt;figure id="figure-ghassan-alregib">
&lt;img src="https://minhungchen.netlify.app/img/authors/head_ga.jpg" alt="" width="100%" >
&lt;figcaption>
Ghassan AlRegib
&lt;/figcaption>
&lt;/figure>
&lt;/a>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;/table></description></item></channel></rss>